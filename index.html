<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Abhishek Banerjee | Cloud Architecture & Data Engineer</title>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link
    href="https://fonts.googleapis.com/css2?family=Manrope:wght@300;400;500;600;700&display=swap"
    rel="stylesheet"
  />
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header class="hero">
    <nav class="nav">
      <div class="logo">AB</div>
      <div class="nav-links">
        <a href="#pipeline">Pipeline</a>
        <a href="#about">About</a>
        <a href="#experience">Experience</a>
        <a href="#skills">Skills</a>
        <a href="#projects">Projects</a>
        <a href="#contact">Contact</a>
      </div>
      <a class="nav-cta" href="https://www.linkedin.com/in/baner29/" target="_blank" rel="noreferrer">
        LinkedIn
      </a>
    </nav>

    <div class="hero-content">
      <p class="eyebrow">Hello, I'm</p>
      <h1>Abhishek Banerjee</h1>
      <p class="subtitle">
        Cloud Architecture & Data Engineer building resilient data platforms, streaming systems, and
        analytics experiences that scale with confidence.
      </p>
      <div class="hero-actions">
        <a class="button primary" href="#contact">Let's connect</a>
        <a class="button ghost" href="https://www.linkedin.com/in/baner29/" target="_blank" rel="noreferrer">
          View LinkedIn
        </a>
      </div>
    </div>
  </header>

  <main>
    <section id="pipeline" class="section pipeline">
      <div class="section-heading">
        <h2>Pipeline Playground</h2>
        <p>
          Scroll to ignite the pipeline. Tap ingredients to drop skills into the boiler and watch how
          data moves from ingestion to a BigQuery-ready plate.
        </p>
      </div>
      <div class="pipeline-grid">
        <div class="pipeline-visual stage-ingestion" aria-live="polite">
          <div class="sky">
            <div class="cloud c1"></div>
            <div class="cloud c2"></div>
            <div class="cloud c3"></div>
          </div>
          <div class="boiler-area">
            <div class="boiler">
              <div class="boiler-liquid"></div>
              <div class="boiler-label">Data Boiler</div>
            </div>
            <div class="stove">
              <div class="flame"></div>
            </div>
          </div>
          <div class="hands">
            <div class="hand hand-left">
              <span class="hand-label">Transform</span>
              <div class="spatula"></div>
            </div>
            <div class="hand hand-right">
              <span class="hand-label">Load</span>
            </div>
          </div>
          <div class="plate">
            <div class="plate-label">BigQuery</div>
            <div class="dish"></div>
          </div>
          <div class="pipeline-status">
            <span class="status-label">Current stage:</span>
            <span class="status-value">Ingestion</span>
          </div>
        </div>
        <div class="pipeline-steps">
          <article class="pipeline-step" data-stage="ingestion">
            <h3>1. Ingestion</h3>
            <p>
              Raw ingredients (skills + toolkits) drop into the boiler. Click a chip to send it down the
              intake funnel.
            </p>
            <div class="ingredient-buttons" role="group" aria-label="Drop ingredients into the pipeline">
              <button type="button" class="ingredient" data-ingredient="Kafka">Kafka</button>
              <button type="button" class="ingredient" data-ingredient="Pub/Sub">Pub/Sub</button>
              <button type="button" class="ingredient" data-ingredient="Airflow">Airflow</button>
              <button type="button" class="ingredient" data-ingredient="Python">Python</button>
            </div>
          </article>
          <article class="pipeline-step" data-stage="processing">
            <h3>2. Processing</h3>
            <p>
              As you scroll, the flame ignites. This layer handles orchestration, reliability, and
              throughput tuning.
            </p>
            <ul>
              <li>Latency optimization and cost-aware compute.</li>
              <li>Observability hooks for every pipeline hop.</li>
              <li>Auto-scaling to meet demand spikes.</li>
            </ul>
          </article>
          <article class="pipeline-step" data-stage="transformation">
            <h3>3. Transformation</h3>
            <p>
              The spatula comes in to enrich, model, and curate data products for analytics and ML.
            </p>
            <ul>
              <li>dbt-style modeling and semantic layers.</li>
              <li>Quality checks, lineage, and governance.</li>
              <li>Reusable templates for data product teams.</li>
            </ul>
          </article>
          <article class="pipeline-step" data-stage="loading">
            <h3>4. Loading</h3>
            <p>
              Two hands plate the meal into a BigQuery-inspired destination. Ready for dashboards,
              experimentation, and decision-making.
            </p>
            <ul>
              <li>BigQuery, Snowflake, and Databricks ready outputs.</li>
              <li>Self-serve analytics and curated datasets.</li>
              <li>Governed access with secure sharing.</li>
            </ul>
          </article>
        </div>
      </div>
    </section>

    <section id="about" class="section">
      <div class="section-heading">
        <h2>About</h2>
        <p>
          I design cloud-native data pipelines that move from raw ingestion to curated, business-ready
          datasets. My work blends platform reliability, cost optimization, and developer enablement so
          teams can ship fast and trust their data.
        </p>
      </div>
      <div class="about-grid">
        <div class="card">
          <h3>Focus Areas</h3>
          <ul>
            <li>Cloud architecture across AWS & GCP with infrastructure-as-code.</li>
            <li>Real-time + batch pipelines with observability baked in.</li>
            <li>Analytics enablement: semantic layers, BI performance, and data products.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Highlights</h3>
          <ul>
            <li>Modernized ingestion + warehouse architectures, cutting latency by 45%.</li>
            <li>Built streaming stacks that sustained 10x event volume growth.</li>
            <li>Enabled 20+ stakeholders to self-serve insights with reusable data foundations.</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="experience" class="section alt">
      <div class="section-heading">
        <h2>Experience</h2>
        <p>Selected leadership moments from cloud architecture and data engineering roles.</p>
      </div>
      <div class="timeline">
        <article class="timeline-item">
          <div class="timeline-meta">
            <span class="role">Lead Cloud Data Engineer</span>
            <span class="company">Cloud Platform Team</span>
            <span class="timeframe">2021 – Present</span>
          </div>
          <div class="timeline-content">
            <p>Architected streaming and batch pipelines powering analytics and ML products.</p>
            <ul>
              <li>Scaled ingestion pipelines to support 10x event growth with zero downtime.</li>
              <li>Introduced data quality and lineage tooling to reduce incident response time.</li>
              <li>Aligned platform reliability with cost optimization for data workloads.</li>
            </ul>
          </div>
        </article>

        <article class="timeline-item">
          <div class="timeline-meta">
            <span class="role">Senior Data Engineer</span>
            <span class="company">Analytics Enablement</span>
            <span class="timeframe">2018 – 2021</span>
          </div>
          <div class="timeline-content">
            <p>Built reusable data products and self-serve analytics foundations.</p>
            <ul>
              <li>Delivered dbt modeling frameworks for faster dashboard delivery.</li>
              <li>Partnered with stakeholders to prioritize metric consistency and trust.</li>
              <li>Automated BigQuery tuning and spend guardrails.</li>
            </ul>
          </div>
        </article>
      </div>
    </section>

    <section id="skills" class="section">
      <div class="section-heading">
        <h2>Skills</h2>
        <p>Cloud, data, and platform engineering toolkit.</p>
      </div>
      <div class="pill-grid">
        <span>AWS</span>
        <span>GCP</span>
        <span>Terraform</span>
        <span>Kubernetes</span>
        <span>BigQuery</span>
        <span>Snowflake</span>
        <span>Databricks</span>
        <span>Kafka</span>
        <span>Pub/Sub</span>
        <span>Airflow</span>
        <span>dbt</span>
        <span>Python</span>
        <span>SQL</span>
        <span>Spark</span>
        <span>CI/CD</span>
      </div>
    </section>

    <section id="projects" class="section alt">
      <div class="section-heading">
        <h2>Projects</h2>
        <p>Signature initiatives across data platforms and analytics enablement.</p>
      </div>
      <div class="project-grid">
        <article class="card">
          <h3>Data Mesh Platform</h3>
          <p>Multi-tenant ingestion and data product templates for distributed teams.</p>
          <div class="tag-row">
            <span>Data Products</span>
            <span>Governance</span>
          </div>
        </article>
        <article class="card">
          <h3>Real-Time Event Hub</h3>
          <p>Streaming ingestion, alerting, and anomaly detection for mission-critical workloads.</p>
          <div class="tag-row">
            <span>Streaming</span>
            <span>Reliability</span>
          </div>
        </article>
        <article class="card">
          <h3>Cost Optimization Toolkit</h3>
          <p>Automated BigQuery + Snowflake tuning with proactive spend guardrails.</p>
          <div class="tag-row">
            <span>FinOps</span>
            <span>Automation</span>
          </div>
        </article>
      </div>
    </section>

    <section id="contact" class="section">
      <div class="section-heading">
        <h2>Contact</h2>
        <p>Ready to connect? Reach out through your preferred channels.</p>
      </div>
      <div class="contact-card">
        <div>
          <h3>Let's talk</h3>
          <p>Open to cloud architecture, data engineering, and analytics enablement collaborations.</p>
        </div>
        <div class="contact-actions">
          <a class="button primary" href="mailto:your.email@example.com">Email me</a>
          <a class="button ghost" href="https://www.linkedin.com/in/baner29/" target="_blank" rel="noreferrer">
            Message on LinkedIn
          </a>
        </div>
      </div>
    </section>
  </main>

  <footer class="footer">
    <p>© 2024 Abhishek Banerjee. All rights reserved.</p>
  </footer>

  <script>
    const pipelineVisual = document.querySelector('.pipeline-visual');
    const statusValue = document.querySelector('.status-value');
    const pipelineSteps = document.querySelectorAll('.pipeline-step');
    const stageMap = {
      ingestion: 'Ingestion',
      processing: 'Processing',
      transformation: 'Transformation',
      loading: 'Loading'
    };

    const setStage = (stage) => {
      if (!pipelineVisual) return;
      pipelineVisual.classList.remove(
        'stage-ingestion',
        'stage-processing',
        'stage-transformation',
        'stage-loading'
      );
      pipelineVisual.classList.add(`stage-${stage}`);
      if (statusValue) {
        statusValue.textContent = stageMap[stage] || 'Ingestion';
      }
    };

    const observer = new IntersectionObserver(
      (entries) => {
        entries.forEach((entry) => {
          if (entry.isIntersecting) {
            setStage(entry.target.dataset.stage);
          }
        });
      },
      { threshold: 0.6 }
    );

    pipelineSteps.forEach((step) => observer.observe(step));

    const ingredientButtons = document.querySelectorAll('.ingredient');
    const boiler = document.querySelector('.boiler');

    ingredientButtons.forEach((button) => {
      button.addEventListener('click', () => {
        if (!boiler) return;
        const chip = document.createElement('span');
        chip.className = 'ingredient-drop';
        chip.textContent = button.dataset.ingredient;
        chip.style.left = `${Math.random() * 60 + 20}%`;
        boiler.appendChild(chip);
        setTimeout(() => chip.remove(), 3000);
      });
    });
  </script>
</body>
</html>
